{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Q_Textblob_News-Classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrKP7lUM__C5"
      },
      "source": [
        "## **Minerando Dados - A maior comunidade de Data Science do Brasil**\n",
        "www.minerandodados.com.br"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHaqz085__DG"
      },
      "source": [
        "* Estudando a Biblioteca TextBlob\n",
        "* Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_psYdaa__DH"
      },
      "source": [
        "# **Classificando documentos usando Textblob**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoLg3A8Z__DH"
      },
      "source": [
        "**Importando a Biblioteca**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQTFHJwK__DI"
      },
      "source": [
        "from textblob import TextBlob\n",
        "import pandas as pd\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HGfBxXz__DK"
      },
      "source": [
        "* Criando um modelo para classificar frases.\n",
        "* Base de dados em português."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MIR1Z-Q__DK"
      },
      "source": [
        "**Ler a base de dados de noticias**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcgaWWp___DL"
      },
      "source": [
        "news = pd.read_csv('news.csv', sep=';', header=None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SkrJ14Bm__DL",
        "outputId": "b173b2e4-8cf1-426b-e587-cdb9a9b5d02e"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O capitão américa aparece sobrevoando São Paul...</td>\n",
              "      <td>verdadeiro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A polarização da população gera guerra civil</td>\n",
              "      <td>fake_news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O Chaves se pronuncia e diz está indignado com...</td>\n",
              "      <td>verdadeiro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Morte do precidenciavel X por acidente de aviao</td>\n",
              "      <td>verdadeiro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Monumento de Brasilia é atacado por manifestan...</td>\n",
              "      <td>fake_news</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0           1\n",
              "0  O capitão américa aparece sobrevoando São Paul...  verdadeiro\n",
              "1       A polarização da população gera guerra civil   fake_news\n",
              "2  O Chaves se pronuncia e diz está indignado com...  verdadeiro\n",
              "3    Morte do precidenciavel X por acidente de aviao  verdadeiro\n",
              "4  Monumento de Brasilia é atacado por manifestan...   fake_news"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkZNPqJz__DM",
        "outputId": "95cb633c-f6cb-47de-a692-b3d2da66590f"
      },
      "source": [
        "news.values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['O capitão américa aparece sobrevoando São Paulo e diz que irá se candidatar',\n",
              "        'verdadeiro'],\n",
              "       ['A polarização da população gera guerra civil', 'fake_news'],\n",
              "       ['O Chaves se pronuncia e diz está indignado com tanta mentira.',\n",
              "        'verdadeiro'],\n",
              "       ['Morte do precidenciavel X por acidente de aviao', 'verdadeiro'],\n",
              "       ['Monumento de Brasilia é atacado por manifestantes e eleicoes seráo canceladas',\n",
              "        'fake_news'],\n",
              "       ['Novo presidente se diz confiante para governar o pais',\n",
              "        'verdadeiro'],\n",
              "       ['Jair Bolsonaro sobe no ranking de rejeicao no nordeste',\n",
              "        'verdadeiro'],\n",
              "       ['Haddad melhora nas pesquisas apos apoio de Lula', 'verdadeiro'],\n",
              "       ['Disputa no segundo turno está cada vez mais acirrada entre os extremos',\n",
              "        'verdadeiro'],\n",
              "       ['Amoedo declara apoio ao PT', 'fake_news'],\n",
              "       ['Manifestantes em Sao Paulo param avenida pedem intervençao militar!',\n",
              "        'fake_news'],\n",
              "       ['Padre Marcelo Rossi diz que irá se candidatar a presidencia',\n",
              "        'fake_news'],\n",
              "       ['Ex presidente Lula consegue habeas Corpus e pode ser candidato',\n",
              "        'fake_news'],\n",
              "       ['Presidente temmer declara apoio ao partido NOVO', 'fake_news'],\n",
              "       ['Mourao declara que é contra o 13 salario e adiantamento de férias de funcionários',\n",
              "        'verdadeiro']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg06uyW3__DM"
      },
      "source": [
        "**Importa o classificador NaiveBayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7o1Vb_c__DN",
        "outputId": "ac344cf4-ab24-40e2-a544-1774d1c429c3"
      },
      "source": [
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJX_QN8f__DN"
      },
      "source": [
        "**Treina o classificador**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjnaF5e2__DN"
      },
      "source": [
        "clf = NaiveBayesClassifier(news.values, format=\"csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2E8JFgJ__DO",
        "outputId": "e630e8fc-eaf3-4d14-c9f9-b870d129cc2a"
      },
      "source": [
        "# modelagem do tipo bag of words\n",
        "clf.extract_features('Chuva declara apoio aos baixinhos')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contains(13)': False,\n",
              " 'contains(A)': False,\n",
              " 'contains(Amoedo)': False,\n",
              " 'contains(Bolsonaro)': False,\n",
              " 'contains(Brasilia)': False,\n",
              " 'contains(Chaves)': False,\n",
              " 'contains(Corpus)': False,\n",
              " 'contains(Disputa)': False,\n",
              " 'contains(Ex)': False,\n",
              " 'contains(Haddad)': False,\n",
              " 'contains(Jair)': False,\n",
              " 'contains(Lula)': False,\n",
              " 'contains(Manifestantes)': False,\n",
              " 'contains(Marcelo)': False,\n",
              " 'contains(Monumento)': False,\n",
              " 'contains(Morte)': False,\n",
              " 'contains(Mourao)': False,\n",
              " 'contains(NOVO)': False,\n",
              " 'contains(Novo)': False,\n",
              " 'contains(O)': False,\n",
              " 'contains(PT)': False,\n",
              " 'contains(Padre)': False,\n",
              " 'contains(Paulo)': False,\n",
              " 'contains(Presidente)': False,\n",
              " 'contains(Rossi)': False,\n",
              " 'contains(Sao)': False,\n",
              " 'contains(São)': False,\n",
              " 'contains(X)': False,\n",
              " 'contains(a)': False,\n",
              " 'contains(acidente)': False,\n",
              " 'contains(acirrada)': False,\n",
              " 'contains(adiantamento)': False,\n",
              " 'contains(américa)': False,\n",
              " 'contains(ao)': False,\n",
              " 'contains(aparece)': False,\n",
              " 'contains(apoio)': True,\n",
              " 'contains(apos)': False,\n",
              " 'contains(atacado)': False,\n",
              " 'contains(avenida)': False,\n",
              " 'contains(aviao)': False,\n",
              " 'contains(cada)': False,\n",
              " 'contains(canceladas)': False,\n",
              " 'contains(candidatar)': False,\n",
              " 'contains(candidato)': False,\n",
              " 'contains(capitão)': False,\n",
              " 'contains(civil)': False,\n",
              " 'contains(com)': False,\n",
              " 'contains(confiante)': False,\n",
              " 'contains(consegue)': False,\n",
              " 'contains(contra)': False,\n",
              " 'contains(da)': False,\n",
              " 'contains(de)': False,\n",
              " 'contains(declara)': True,\n",
              " 'contains(diz)': False,\n",
              " 'contains(do)': False,\n",
              " 'contains(e)': False,\n",
              " 'contains(eleicoes)': False,\n",
              " 'contains(em)': False,\n",
              " 'contains(entre)': False,\n",
              " 'contains(está)': False,\n",
              " 'contains(extremos)': False,\n",
              " 'contains(funcionários)': False,\n",
              " 'contains(férias)': False,\n",
              " 'contains(gera)': False,\n",
              " 'contains(governar)': False,\n",
              " 'contains(guerra)': False,\n",
              " 'contains(habeas)': False,\n",
              " 'contains(indignado)': False,\n",
              " 'contains(intervençao)': False,\n",
              " 'contains(irá)': False,\n",
              " 'contains(mais)': False,\n",
              " 'contains(manifestantes)': False,\n",
              " 'contains(melhora)': False,\n",
              " 'contains(mentira)': False,\n",
              " 'contains(militar)': False,\n",
              " 'contains(nas)': False,\n",
              " 'contains(no)': False,\n",
              " 'contains(nordeste)': False,\n",
              " 'contains(o)': False,\n",
              " 'contains(os)': False,\n",
              " 'contains(pais)': False,\n",
              " 'contains(para)': False,\n",
              " 'contains(param)': False,\n",
              " 'contains(partido)': False,\n",
              " 'contains(pedem)': False,\n",
              " 'contains(pesquisas)': False,\n",
              " 'contains(pode)': False,\n",
              " 'contains(polarização)': False,\n",
              " 'contains(população)': False,\n",
              " 'contains(por)': False,\n",
              " 'contains(precidenciavel)': False,\n",
              " 'contains(presidencia)': False,\n",
              " 'contains(presidente)': False,\n",
              " 'contains(pronuncia)': False,\n",
              " 'contains(que)': False,\n",
              " 'contains(ranking)': False,\n",
              " 'contains(rejeicao)': False,\n",
              " 'contains(salario)': False,\n",
              " 'contains(se)': False,\n",
              " 'contains(segundo)': False,\n",
              " 'contains(ser)': False,\n",
              " 'contains(seráo)': False,\n",
              " 'contains(sobe)': False,\n",
              " 'contains(sobrevoando)': False,\n",
              " 'contains(tanta)': False,\n",
              " 'contains(temmer)': False,\n",
              " 'contains(turno)': False,\n",
              " 'contains(vez)': False,\n",
              " 'contains(é)': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zx4C8nlx__DP",
        "outputId": "fa037c7d-94ff-4819-bfab-7efbc27f1210"
      },
      "source": [
        "clf.classify('Chuva declara apoio aos baixinhos')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fake_news'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MGq5WLMY__DP",
        "outputId": "dd980743-8878-4fa5-8377-bc3777c81eff"
      },
      "source": [
        "clf.classify('Presidente Temmer declara apoio a candidato do PSDB')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fake_news'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O8rG_eO7__DQ",
        "outputId": "e0a1f095-7a75-432a-9cdd-a5969501dc5a"
      },
      "source": [
        "clf.classify('Disputa entre presidenciais sera mesmo no segundo turno')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'verdadeiro'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_7Ddfz7__DR"
      },
      "source": [
        "**Distribuicao das Probabilidades**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqzVJsVY__DR"
      },
      "source": [
        "dist_prob = clf.prob_classify('Padre Marcelo Rossi se pronuncia e diz que irá se candidatar')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GKDZ2AA__DS",
        "outputId": "761642a4-833b-44fe-8ba7-3d9db8ebec0e"
      },
      "source": [
        "dist_prob.prob('fake_news')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8336538270304874"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXXoM8_T__DS",
        "outputId": "88444f2a-49cb-48a2-86a7-3f4480eeb55e"
      },
      "source": [
        "dist_prob.prob('verdadeiro')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1663461729695134"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BI2Hf6EF7dj"
      },
      "source": [
        "    A frase acima tem probabilidade de ser fake_news de 83%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yJYzsbKM__DS",
        "outputId": "7edb18e7-8b33-460b-963e-d25bb1d10401"
      },
      "source": [
        "dist_prob.max()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fake_news'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIXQC11I__DT"
      },
      "source": [
        "**Avaliando o classificador usando um conjunto de validação**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3kGu2Pf__DT"
      },
      "source": [
        "validacao = [\n",
        "     ('O governo temmer propoe reforma trabalhista', 'verdadeiro'),\n",
        "     ('Capitão america é visto em campanha eleitoral do partido NOVO', 'fake_news'),\n",
        "     (\"Lula é solto essa madrugada\", 'fake_news'),\n",
        "     (\"Jair Bolsonaro melhora nas pesquisas após atentado.\", 'verdadeiro')\n",
        "]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIqWIfz5__DT"
      },
      "source": [
        "**Visualizando a Acurácia do Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqkQGK_N__DU",
        "outputId": "f984475f-4d18-4469-b39b-cdaf8a7ccba2"
      },
      "source": [
        "clf.accuracy(validacao)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2zQBb0j__DU",
        "outputId": "e4334b8c-b84d-4cf3-dccd-f2c62fe8eebd"
      },
      "source": [
        "for i in validacao:\n",
        "    print (i[0], clf.classify(i[0]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O governo temmer propoe reforma trabalhista fake_news\n",
            "Capitão america é visto em campanha eleitoral do partido NOVO fake_news\n",
            "Lula é solto essa madrugada fake_news\n",
            "Jair Bolsonaro melhora nas pesquisas após atentado. verdadeiro\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPw62Sb6HL84"
      },
      "source": [
        "    Vemos a classificação do nosso modelo para cada frase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOHZFFUb__DU",
        "outputId": "c6a3a346-f530-465d-8d6a-5a529fe8199d"
      },
      "source": [
        "# Features mais informativas\n",
        "print (clf.show_informative_features(20))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "            contains(de) = True           verdad : fake_n =      2.7 : 1.0\n",
            "           contains(diz) = True           verdad : fake_n =      2.1 : 1.0\n",
            "            contains(se) = True           verdad : fake_n =      2.1 : 1.0\n",
            "         contains(apoio) = True           fake_n : verdad =      1.9 : 1.0\n",
            "       contains(declara) = True           fake_n : verdad =      1.9 : 1.0\n",
            "            contains(de) = False          fake_n : verdad =      1.6 : 1.0\n",
            "           contains(que) = True           verdad : fake_n =      1.5 : 1.0\n",
            "            contains(ao) = False          verdad : fake_n =      1.4 : 1.0\n",
            "           contains(diz) = False          fake_n : verdad =      1.3 : 1.0\n",
            "            contains(se) = False          fake_n : verdad =      1.3 : 1.0\n",
            "             contains(o) = False          fake_n : verdad =      1.3 : 1.0\n",
            "          contains(está) = False          fake_n : verdad =      1.3 : 1.0\n",
            "             contains(O) = False          fake_n : verdad =      1.3 : 1.0\n",
            "            contains(no) = False          fake_n : verdad =      1.3 : 1.0\n",
            "             contains(e) = True           verdad : fake_n =      1.2 : 1.0\n",
            "         contains(apoio) = False          verdad : fake_n =      1.2 : 1.0\n",
            "       contains(declara) = False          verdad : fake_n =      1.2 : 1.0\n",
            "            contains(da) = False          verdad : fake_n =      1.2 : 1.0\n",
            " contains(manifestantes) = False          verdad : fake_n =      1.2 : 1.0\n",
            "         contains(Padre) = False          verdad : fake_n =      1.2 : 1.0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ4Ksda2HRxx"
      },
      "source": [
        "    Vemos que quando temos algumas palavras, por exemplo: Quando nao se tem a palavra \"Padre\", \n",
        "    temos a probabilidade de 1.2x de ser verdadeira."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-32bMBaVG160"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}